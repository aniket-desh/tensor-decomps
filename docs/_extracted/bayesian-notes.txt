Bayesian Maximum Likelihood Estimation for CP Decomposition

Edgar Solomonik

December 18, 2025

1
New Model

Let N(Âµ, M) denote a multidimensional normal distribution with mean Âµ and covariance matrix
M. Let [K] = {1, . . . , K} and let âˆ—denote the Hadamard/pointwise product. For low-rank matrix
factorization or CP decomposition, the Frobenius norm error metric assumes a Gaussian distribution of the error. In the matrix case, this means that for A âˆˆRnÃ—n, we assume that A is obtained
from some U, V , as
vec(A) = vec(UV T ) + ÏµN(0, I),

then for any Ïµ â‰¥0,
arg min
U,V
âˆ¥A âˆ’UV T âˆ¥F = arg max
U,V
p(U, V |A),

since the most likely U, V is given by the value of A âˆ’UV T that is most likely to be taken on by
ÏµN(0, I), i.e.,
arg max
U,V
p(U, V |A) = arg max
U,V
p(ÏµN(0, I) = A âˆ’UV T )

and

p(ÏµN(0, I) = A âˆ’UV T ) = (2Ï€)âˆ’n2

Ïµ
exp{âˆ’1

2Ïµ2âˆ¥A âˆ’UV T âˆ¥2
F }.

Hence, the log of the probability (log likelihood) is proportional to the negation of the Frobenius
norm error.
We could instead assume that the distribution of the noise has the same covariance as the signal
/ quantity of interest. If we assume each column of U and V are samples of some distribution, then
their sample covariance matrices are 1

RUUT and 1

RV V T . In the matrix case, we could again write
a corresponding probabilistic model,

vec(A) = vec(UV T ) + ÏµN(0, (UUT + (I âˆ’UU+)) âŠ—(V V T + (I âˆ’V V +))),

in which we assume noise outside of the span of U and V is independent (identity covariance).

vec(A) = vec(UV T ) + Ïµ/K
X

i
Uxi âŠ—V yi,

where xi and yi are random vectors whose entries are elementwise independent and normally
distributed. In this case, finding the most like U and V corresponds to minimizing the Mahalanobis
distance,

arg max
U,V
p(U, V |A) = arg min
U,V
âˆ¥vec(A âˆ’UV T )âˆ¥((UUT +(Iâˆ’UU+))âŠ—(V V T +(Iâˆ’V V +)))âˆ’1.
(1)

1

arg max
U,V
p(U, V |A) = arg min
U,V
âˆ¥vec(A âˆ’UV T )âˆ¥(UUT âŠ—V V T )âˆ’1.
(2)

In the matrix case, the truncated SVD results in vec(A âˆ’UV T ) âŠ¥span(U) âŠ—Rn and vec(A âˆ’
UV T ) âŠ¥Rn âŠ—span(V ), so it also minimizes Mahalanobis distance in this model. In the tensor
case, the AMDM algorithm minimizes Mahalanobis distance in an alternating manner and hence,
if it convergence successfully, it reaches a locally optimal solution to likelihood maximization.
We now propose a model to justify why the noise term might follow a distribution with the
same covariance as the sample covariance obtained by considering the columns of the decomposition
factors. The model assumes that each rank-1 term in the decomposition of T is obtained as a sum
of identical copies thereof, rescaled and perturbed in a relative way. Specifically, given a tensor
of order N, T âˆˆRn1Ã—...Ã—nN , consider the inverse problem of reconstructing U(1), . . . , U(N) where
U(i) =

u(i,1)
. . .
u(i,R)
, such that for some Râ€² > R,

T =

Râ€²
X

j=1
Î±j

N
O

i=1
(u(i,rj) + u(i,rj) âˆ—ÏµN(0, I)), where âˆ€r âˆˆ[R],
X

j,rj=r
Î±j = 1.

TODO 1: Show that to leading order in Ïµ for sufficiently large Râ€² and small Î±js, this model is
equivalent to (2) generalized to the tensor case.

TODO 2: Actually run some experiments applying AMDM to tensors generated based on this
probabilistic model and see if it gives a better approximation of the Us than ALS.

Additional thoughts (Edgar): the introduction of Râ€² terms is needed so that the perturbed
rank-1 terms do not themselves minimize the objective, since they do not increase rank, hence the
extra terms are needed for averaging. Perhaps there are other / better ways to model this. In
particular the averaging seems to correspond to a quadrature rule, so perhaps one can instead say
something like

T =

R
X

r=1
Tr,
Tr = 1

|â„¦|

Z

â„¦

N
O

i=1
(u(i,r) + u(i,r) âˆ—Ï‡(Î¸))dÎ¸,

with something like Ï‡(Î¸) = ÏµN(0, I)(Î¸) (having in mind independent noise for any Î¸, which is
unrealistic). Perhaps there ways to think of the noise in terms of a more general inverse problem
with an integral equation / handle a general class of Ï‡(Î¸) and possibly also make u or du/dÎ¸
dependent on Î¸.

Consider the following perturbation model

T =

R
X

j=1

N
O

i=1
u(i,rj) +

K
X

k=1
Ïµ/K

N
O

i=1
U(i)x(i,k),

where K is something larger than R, U(i) =

u(i,1)
. . .
u(i,R)
and x(i,k) are random vectors whose
entries are elementwise independent and normally distributed. We can show that for any given U(i),
the noise will actually follow the effect of covariance given by the kind of empirical covariance of
U(i), while in the following model the noise follows the true covariance.

1.1
Notes on Application to Probability Density Basis Coefficient Estimation

Suppose we have a Bayesian model to estimate a probability density of the form,

p(x, y) = âŸ¨AT Ïˆ(x), BÏ•(y)âŸ©=
X

i,j,r
airbjrÏˆi(x)Ï•j(y)

2

where we fix a basis a prior defined by vector valued functions Ïˆ, Ï• : R â†’RN. Consider the random
variable, Z = Ïˆ(x)Ï•(y)T where (x, y) âˆ¼p(x, y). Then given m independent samples {(xk, yk)}m
k=1
of p(x, y), we have that for

M = 1

m

m
X

k=1
Ïˆ(xk)Ï•(yk)T

that
E[Z] = WÏˆABT WÏ•, where Wf[i, j] =
Z

z
fi(z)fj(z)dz.

If we treat the m samples as random variables, E[M] = E[Z] and the variance is M[M] = 1

kM[Z]
may be used to estimate ABT .
We could further ask which choice of A and B would yield the probabilistic model (define
p(x, y)) that is most likely to produce M (to solve the maximum likelihood problem given only
M). Since M is a sum of iid samples, as m â†’âˆž, M converges to a multidimensional Gaussian
distribution. Hence, we know that as m â†’âˆž,

p(M|A, B) âˆeâˆ’1

2 xT V âˆ’1x, x = vec(M âˆ’ABT ), V = 1

m Â· M(x,y)âˆ¼p(x,y)[Ïˆ(x) âŠ—Ï•(y)].

However, the covariance of Ïˆ(x) âŠ—Ï•(y) in p(x, y) is a bit difficult to characterize. This random
variable is a tensor product of two random variables, but its covariance matrix also has terms that
depend on the expectations of the two random variables. Further, the marginal distribution of
p(x, y) is of the form,

p(x) =
Z

y
p(x, y)dy = âŸ¨u, Ïˆ(x)âŸ©,

for some vector u. Hence its covariance appears to be defined by rank-1 terms, as apposed to AAT ,
which we would want for the current form of Mahalanobis distance minimization.
We could devise new distance functions based on something like the above, or try to consider
other parameterization of the distribution. I was considering models like

p(x, y) =
X

i,j,r
airbjrÏˆir(x)Ï•jr(y)

where Ïˆir and Ïˆjs for each i Ì¸= j have disjoint support (each choice of i index corresponds to a
segment of x). Though I am not sure that is the best restriction to apply. The marginal distribution
would then involve all of A and B, but its unclear if the resulting formulations make sense in terms
of M, etc.

2
Prior Work

2.1
Theory of Expectation Maximization

2.2
Covariance Estimation and Expectation Maximization Applications

Prior works have applied the EM algorithm to estimation of structured covariance matrices. In [1],
the covariance matrix is parameterized by a vector and EM is used to derive a tractable iterative update, though the update still requires iterative optimization and varies depending on the
underlying model.

3

3
Maximum Likelihood Estimation with CP Decomposition

3.1
Problem Definition: Empirical Bayes Model for CP Decomposition

Given tensor of order N, T âˆˆRn1Ã—...Ã—nN , we model T as a sum of R i.i.d. samples from a distribution
of rank-1 tensors, plus noise,

T = N + 1

R

R
X

r=1

N
O

i=1
u(i,r),

where each u(i,r) is an independent sample of a multivariate normal random variable u(i).
We
assume the term N, which may represent noise or less significant information, is also a sum of
samples of rank-1 tensors from a rescaled distribution with the same covariance but zero mean, i.e.,
for some k, Ïµ,

N = Ïµ/k

k
X

r=1

N
O

i=1
Ëœu(i,r),
Ëœu(i,r) âˆ¼u(i) âˆ’E[u(i)].

Given T, we seek to recover the most likely samples u(i,r), for i âˆˆ1, . . . N, r âˆˆ1, . . . R, by estimating
the covariance matrices M[u(i)]. Since the samples composing the noise are independent and zero
mean,

M[N] = Ïµ2/kM
h N
O

i=1
Ëœu(i,r)i
= Ïµ2/k

N
O

i=1
M
h
u(i)i

Are we missing a factor of k due to sum of covariances? Also note that T and u(i) do not have
the same covariance as above if their mean is nonzero. We parameterize M[u(i)] = Î±I + (Î²I +
(1/R)XXT )âˆ’1, where the prior distribution of X is

p(X) = C det(VÎ±(X))âˆ’R/2
R
Y

i=1
exp{âˆ’1

2Î² Tr(XT X)},

for some Î±, Î² > 0, with appropriate choice of constant C. Then, letting U(i) =

u(i,1)
Â· Â· Â·
u(i,R)
,
Î¸ = {U(i)}N
i=1, and Î¨ = {X(i)}N
i=1, the joint probability density function is

p(Î¸, Î¨, T) = p(T|Î¸, Î¨)p(Î¸|Î¨)p(Î¨).

We seek to perform maximum likelihood estimation on the samples Î¸, given T, i.e., we seek to
maximize the marginal likelihood,

L(Î¸|T) = p(T|Î¸) =
Z
p(T|Î¸, Î¨)p(Î¨|Î¸)dÎ¨.

3.2
Expectation Maximization Algorithm

FIXME: EM would usually define Q relative to expectation over the distribution p(Î¨|Â¯Î¸, T). Note
that p(Î¨|Â¯Î¸, T) Ì¸= p(Î¨|Â¯Î¸), because N is fixed given Â¯Î¸ and T, but the probability of Î¨ is dependent
on N if N is distributed in the same fashion.
At each iteration, given the current estimate of parameters Â¯Î¸ the EM algorithm maximizes Î¸ in
the expectation (over Î¨ conditioned on Â¯Î¸) of the log likelihood of Î¨ and T, conditioned on Î¸,

Q(Î¸, Â¯Î¸) =
Z
log(p(Î¨, T|Î¸))p(Î¨|Â¯Î¸, T)dÎ¨.

4

FIXME desired form is below, standard form is above

Ë†Q(Î¸, Â¯Î¸) =
Z
log(p(T|Î¨, Î¸))p(Î¨|Â¯Î¸)dÎ¨.

Note that, p(T|Î¨, Î¸) = p(N = T âˆ’T(Î¸)|Î¨) where T(Î¸) is the tensor constructed from the CP
factors contained in Î¸. Then, we have that

log p(T|Î¨, Î¸) = âˆ’1

2 vec(T âˆ’T(Î¸))T KÎ¨ vec(T âˆ’T(Î¸)),
where
KÎ¨ =

N
O

i=1
K(i)
X(i),

So we have, with the desired form of Q, that,

Q(Î¸, Â¯Î¸) = âˆ’1

2 vec(T âˆ’T(Î¸))T
 Z
KÎ¨p(Î¨|Â¯Î¸)dÎ¨

vec(T âˆ’T(Î¸)) = log p(T|Ep(Î¨|Â¯Î¸)[KÎ¨], Î¸).

Therefore, the expectation step in the EM algorithm amounts to finding the expected value of KÎ¨
given the current parameters Â¯Î¸. Since the samples along each mode of the tensor are independent,
Ep(Î¨|Â¯Î¸)[KÎ¨] = NN
i=1 Ep(X(i)|U(i))[K(i)
X(i)]. Hence, we next proceed to show that, if E[u(i)] = 0, the

regularized form of the inverse of the sample covariance matrix of each X(i), K(i)
X(i), is the conditional
expected value of the inverse of the covariance matrix given U(i) and the specified prior distribution
of X(i). With that, Q(Î¸, Â¯Î¸) is shown to be the same objective function as that optimized by the
AMDM algorithm [3].

3.3
Sample Covariance Matrix from Conditional Expectation

We now derive a parameterization of covariance matrices such that the conditional expectation
of the regularized inverse of the covariance matrix given the observed samples is the regularized
inverse of the sample covariance matrix. In the following theorem, we use the shorthand notation,

VÎ³(W) = Î³I +
1
#cols(W)WW T .

Note that âˆ¥VÎ³(W)âˆ’1âˆ¥2 â‰¤1/Î³.

Theorem 1. Given a set of R samples a1, . . . , aR of an m-dimensional normal distribution Y with
E[Y ] = 0, let A =

a1
Â· Â· Â·
aR

, then the covariance matrix Z = M[Y ], satisfies

E[Zâˆ’1|A] = Î±I + VÎ²(A)âˆ’1,

if the prior distribution for Z is defined by random matrix X âˆˆRmÃ—R so Z = VÎ±(X)âˆ’1 and
p(X) = C det(VÎ±(X))âˆ’R/2 QR
i=1 exp{âˆ’1

2Î² Tr(XT X)}, for any Î±, Î² > 0, with appropriate choice of
constant C.

Proof. First, note that for any Î±, Î² > 0, p(X) is Lebesgue integrable (for constant Î±, Î² there exists
a suitable normalization constant C to make p(X) a valid probability distribution). Using Bayes
theorem for continuous random variables [2],

E[Zâˆ’1|A] = E[VÎ±(X)|A] =
Z

RmÃ—R VÎ±(X)p(X|A)dX

=
Z

RmÃ—R VÎ±(X)p(A|X)p(X)/p(A)dX,

5

where p(A) is defined based on the prior distribution p(X),

p(A) =
Z

RmÃ—R p(A|X)p(X)dX =
Z

RmÃ—R p(X)

R
Y

i=1
p(ai|X)dX

= (2Ï€)âˆ’mR/2
Z

RmÃ—R p(X)

R
Y

i=1
det(VÎ±(X))1/2 exp{âˆ’1

2aT
i VÎ±(X)ai}dX

= (2Ï€)âˆ’mR/2
Z

RmÃ—R p(X) det(VÎ±(X))R/2 exp{âˆ’1

2 Tr(AT VÎ±(X)A)}dX

= (2Ï€)âˆ’mR/2
Z

RmÃ—R exp{âˆ’1

2 Tr(AT VÎ±(X)A)}

R
Y

i=1
exp{âˆ’1

2Î²xT
i xi}dX

= (2Ï€)âˆ’mR/2
Z

RmÃ—R exp{âˆ’1

2 Tr(Î±AT A + (1/R)AT XXT A + Î²XT X)}dX

= (2Ï€)âˆ’mR/2 exp{Tr(âˆ’1

2Î±AT A)}
Z

RmÃ—R exp{âˆ’1

2 Tr(XT VÎ²(A)X)}dX

= (2Ï€)âˆ’mR/2 exp{Tr(âˆ’1

2Î±AT A)}
 Z

Rm exp{âˆ’1

2xT VÎ²(A)x}dx
R

= C exp{Tr(âˆ’1

2Î±AT A)}/ det(VÎ²(A))R/2.

Note the analogy between the forms of p(X) and p(A), which motivates the paramterization of Z
by X. We can similarly relate E[Zâˆ’1|A] to the covariance matrix of a Gaussian distribution,

E[Zâˆ’1|A] =
det(VÎ²(A))R/2

C exp{Tr(âˆ’1

2Î±AT A)} Â·
Z

RmÃ—R VÎ±(X)p(A|X)p(X)dX

= (2Ï€)âˆ’mR/2 det(VÎ²(A))R/2

C exp{Tr(âˆ’1

2Î±AT A)}
Â·
Z

RmÃ—R VÎ±(X)p(X)

R
Y

i=1
det(VÎ±(X))1/2 exp{âˆ’1

2aT
i VÎ±(X)ai}dX

= (2Ï€)âˆ’mR/2 det(VÎ²(A))R/2

exp{Tr(âˆ’1

2Î±AT A)}
Â·
Z

RmÃ—R VÎ±(X)

R
Y

i=1
exp{âˆ’1

2Î²xT
i xi} exp{âˆ’1

2aT
i VÎ±(X)ai}dX

= (2Ï€)âˆ’mR/2 det(VÎ²(A))R/2 Â·
Z

RmÃ—R VÎ±(X)

R
Y

i=1
exp{âˆ’1

2xT
i VÎ²(A)xi}dX

= Î±I + (2Ï€)âˆ’mR/2 det(VÎ²(A))R/2 Â·
Z

RmÃ—R

 1

R

R
X

j=1
xjxT
j

 R
Y

i=1
exp{âˆ’1

2xT
i VÎ²(A)xi}dX

= Î±I + (2Ï€)âˆ’m/2 det(VÎ²(A))1/2 Â·
Z

Rm xxT exp{âˆ’1

2xT VÎ²(A)x}dx

= Î±I + VÎ²(A)âˆ’1.

The normalization by det(Î±I + XXT )âˆ’R/2 in the prior distribution of X in Theorem 1 is motivated by the proof method, but also has the following intuitive interpretation as an uninformative
prior. Consider the probability density of the tensor product of the R samples composing A for
a fixed X, pX(a1 âŠ—Â· Â· Â· âŠ—aR) = pX(a1) Â· Â· Â· pX(aR).
For a fixed X, the generalized variance of

6

a1 âŠ—Â· Â· Â· âŠ—ar is then det(Z)R = det(Î±I + XXT )âˆ’R. Hence, in the theorem, the prior distribution
probability of the covariance matrices is defined to be proportional to the generalized variance of
the joint distribution of the R samples, which means that the distribution of log det(Z) is uniform
on R modulo the regularization term (which is needed to ensure a valid probability distribution).
The regularization may be avoided altogether by assuming an improper prior distribution for p(X)
(the uniform â€˜distributionâ€™ over RmÃ—R).

3.4
Expectation Estimation

Since u(1), . . . , u(N) are independent,

E[

N
O

i=1
u(i)] =

N
Y

i=1
E[u(i)].

Assuming known covariance matrices, M[u(i)], for i = 1, . . . , N, we also have M[NN
i=1 u(i)]. Then,
we have that p(E[u(1)] = Î·(1), . . . , E[u(N)] = Î·(N)) is maximized whenever the we have minimized
the probability of deviation,

p

N + 1

R

R
X

r=1

N
O

i=1
u(i,r) = T âˆ’

N
O

i=1
Î·(i)


= const Â· exp

âˆ’1

2 vec

T âˆ’

N
O

i=1
Î·(i)
T
M
 N
O

i=1
u(i)
âˆ’1
vec

T âˆ’

N
O

i=1
Î·(i)

.

The logarithm of the above (log likelihood) implies that finding the best estimation of the expectation of {u(i)}N
i=1, amounts to solving the Mahalanobis distance rank-1 approximation problem,

min
Î·(1),...,Î·(N)

vec

T âˆ’

N
O

i=1
Î·(i)

M[NN
i=1 u(i)]âˆ’1
.

References

[1] A. Aubry, A. De Maio, S. Marano, and M. Rosamilia. Structured covariance matrix estimation with missing-(complex) data for radar applications via expectation-maximization. IEEE
Transactions on Signal Processing, 69:5920â€“5934, 2021.

[2] A. N. Kolmogorov. Foundations of the theory of probability. Chelsea Publishing Company, New
York, 1950.

[3] N. Singh and E. Solomonik. Alternating Mahalanobis distance minimization for accurate and
well-conditioned CP decomposition.
SIAM Journal on Scientific Computing, 45(6):A2781â€“
A2812, 2023.

7

